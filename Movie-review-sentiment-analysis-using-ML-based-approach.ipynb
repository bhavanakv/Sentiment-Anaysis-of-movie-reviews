{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the reviews from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativeReviewFile = '/home/bhavana/Desktop/rt-polaritydata/rt-polarity.neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(negativeReviewFile,'r',errors='ignore') as f:\n",
    "    negativeReviews = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveReviewFile = '/home/bhavana/Desktop/rt-polaritydata/rt-polarity.pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(positiveReviewFile,'r',errors='ignore') as f:\n",
    "    positiveReviews = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positiveReviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the data into training set and test data. First 2500 records are used for training and next 2500 records are used for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPositiveReviews = positiveReviews[:split]\n",
    "trainNegativeReviews = negativeReviews[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPositiveReviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPositiveReviews = positiveReviews[split+1:]\n",
    "testNegativeReviews = negativeReviews[split+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVocabulary():\n",
    "    positiveWordList = [word for line in trainPositiveReviews for word in line.split()]\n",
    "    negativeWordList = [word for line in trainNegativeReviews for word in line.split()]\n",
    "    allWordList = [item for sublist in [positiveWordList,negativeWordList] for item in sublist]\n",
    "    allWordSet = list(set(allWordList))\n",
    "    vocabulary = allWordSet\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14089"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = getVocabulary()\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disingenuous'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'jean' in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used as function object in the training step\n",
    "def extract_features(review):\n",
    "    review_words = set(review)\n",
    "    features = {}\n",
    "    for word in vocabulary:\n",
    "        features[word] = (word in review_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingData():\n",
    "    negTaggedNegativeReviews = [{'review': oneReview.split(),'label': 'negative'} for oneReview in trainNegativeReviews]\n",
    "    posTaggedPositiveReviews = [{'review': oneReview.split(),'label': 'positive'} for oneReview in trainPositiveReviews]\n",
    "    fullTaggedReviews = [item for sublist in [posTaggedPositiveReviews,negTaggedNegativeReviews] for item in sublist]\n",
    "    trainingData = [(review['review'],review['label']) for review in fullTaggedReviews]\n",
    "    return trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = getTrainingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simplistic', ',', 'silly', 'and', 'tedious', '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData[2500][0] #Here we get the review and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData[2800][1] #Here we get only label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainedNBClassifier(extract_features, trainingData):\n",
    "    trainingFeatures = nltk.classify.apply_features(extract_features,trainingData) # Training data is converted into feature vector \n",
    "    Classifier = nltk.NaiveBayesClassifier.train(trainingFeatures)\n",
    "    return Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Classifier = getTrainedNBClassifier(extract_features, trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesSentimentAnalyzer(review):\n",
    "    problemInstance = list(review.split())\n",
    "    problemFeatures = extract_features(problemInstance)\n",
    "    return Classifier.classify(problemFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveBayesSentimentAnalyzer(\"What an amazing movie!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveBayesSentimentAnalyzer(\"What a terrible movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTestReviewSentiments(naiveBayesSentimentAnalyzer):\n",
    "    testNegResults = [naiveBayesSentimentAnalyzer(review) for review in testNegativeReviews]\n",
    "    testPosResults = [naiveBayesSentimentAnalyzer(review) for review in testPositiveReviews]\n",
    "    labelToNum = {'positive':1,'negative':-1}\n",
    "    numericNegResults = [labelToNum[x] for x in testNegResults]\n",
    "    numericPosResults = [labelToNum[x] for x in testPosResults]\n",
    "    return {'results-on-positive':numericPosResults, 'results-on-negative':numericNegResults}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runDiagnostics(reviewResult):\n",
    "    positiveReviewsResult = reviewResult['results-on-positive']\n",
    "    negativeReviewsResult = reviewResult['results-on-negative']\n",
    "    numTruePositive = sum(x > 0 for x in positiveReviewsResult)\n",
    "    numTrueNegative = sum(x < 0 for x in negativeReviewsResult)\n",
    "    TruePositive = float(numTruePositive)/len(positiveReviewsResult)\n",
    "    TrueNegative = float(numTrueNegative)/len(negativeReviewsResult)\n",
    "    totalAccurate = numTrueNegative + numTruePositive\n",
    "    total = len(positiveReviewsResult) + len(negativeReviewsResult)\n",
    "    print(\"Accuracy on positive reviews: \"+\"%.2f\" % (TruePositive*100)+\"%\")\n",
    "    print(\"Accuracy on negative reviews: \"+\"%.2f\" % (TrueNegative*100)+\"%\")\n",
    "    print(\"Overall accuracy: \"+\"%.2f\" % (totalAccurate*100/total) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on positive reviews: 73.53%\n",
      "Accuracy on negative reviews: 77.07%\n",
      "Overall accuracy: 75.30%\n"
     ]
    }
   ],
   "source": [
    "runDiagnostics(getTestReviewSentiments(naiveBayesSentimentAnalyzer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
